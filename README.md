# Spider
> 本仓库计划用于记录爬虫相关实践。

## 爬虫难点及解决方案

### 网站采取反爬策略
- 模拟浏览器行为。

### 网站模板定期改动
- 不同配置文件配置不同网站的模板规则。
- 数据库存储不同网站的模板规则。

### 网站 URL 抓取失败
- HttpClient 默认处理方式。
- Storm 实时解析失败日志，将失败 URL 重新加入爬取仓库，一般超过 3 次就放弃。

### 网站频繁抓取导致 IP 被封
- 购买代理 IP 库，随机获取 IP 抓取数据。
- 部署多个应用分别抓取，降低单节点访问频率。
- 设置每个页面抓取时间间隔，降低被封概率。
